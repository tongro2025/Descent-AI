# Multimodal Descent: ORI-based Discrepancy Detection
# Kaggle BigQuery AI Hackathon 2024

import pandas as pd
import numpy as np
from google.cloud import bigquery
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display, HTML

# BigQuery í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = bigquery.Client()

# í”„ë¡œì íŠ¸ ì„¤ì •
PROJECT_ID = "your-project-id"  # ì‹¤ì œ í”„ë¡œì íŠ¸ IDë¡œ ë³€ê²½
DATASET_ID = "descent_demo"

print("ğŸš€ Multimodal Descent: ORI-based Discrepancy Detection")
print("=" * 60)

# 1. ë°ì´í„°ì…‹ ìƒì„±
print("\nğŸ“Š 1. ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
create_dataset_sql = f"""
CREATE SCHEMA IF NOT EXISTS `{PROJECT_ID}.{DATASET_ID}`;
"""
client.query(create_dataset_sql).result()
print("âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")

# 2. ìŠ¤í‚¤ë§ˆ ìƒì„±
print("\nğŸ—ï¸ 2. ìŠ¤í‚¤ë§ˆ ìƒì„± ì¤‘...")
schema_sql = f"""
CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.raw_texts` (
  id STRING,
  body STRING,
  kind STRING,
  meta JSON
);

CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.feat_struct` (
  id STRING,
  f1 FLOAT64, f2 FLOAT64, f3 FLOAT64,
  meta JSON
);

CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.emb_view_t` (
  id STRING, 
  vec VECTOR<FLOAT32>
);

CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.feat_struct_vec` (
  id STRING, 
  vec VECTOR<FLOAT32>
);

CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.emb_stitched` (
  key STRING, 
  vec VECTOR<FLOAT32>,
  alpha FLOAT64, 
  beta FLOAT64
);
"""
client.query(schema_sql).result()
print("âœ… ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")

# 3. ìƒ˜í”Œ ë°ì´í„° ì‚½ì…
print("\nğŸ“ 3. ìƒ˜í”Œ ë°ì´í„° ì‚½ì… ì¤‘...")
sample_data_sql = f"""
INSERT INTO `{PROJECT_ID}.{DATASET_ID}.raw_texts` (id, body, kind, meta) VALUES
  ('A100', 'ì œí’ˆ A100ì˜ í¬ì¥ ì´ë¯¸ì§€ì—ëŠ” ì¼€ì´ë¸” 2ê°œê°€ ë³´ì´ë‚˜, ì„¤ëª…ì—ëŠ” 1ê°œë¡œ ê¸°ì¬ë˜ì–´ ìˆìŒ', 'ticket', JSON '{{"source":"cs"}}'),
  ('A200', 'A200 ë§¤ë‰´ì–¼ì— ìµœëŒ€ ì „ë ¥ 120W í‘œê¸°. ì›¹ ì„¤ëª…ì€ 90W.', 'ticket', JSON '{{"source":"cs"}}'),
  ('A300', 'A300 ëª¨ë¸ ì‚¬ì§„ì—ì„œ ë²„íŠ¼ì´ ì¢Œì¸¡ì— ìˆìœ¼ë‚˜ ìŠ¤í™ì€ ìš°ì¸¡ì´ë¼ê³  ëª…ì‹œ', 'ticket', JSON '{{"source":"cs"}}'),
  ('B100', 'B100 íŒ¨í‚¤ì§€ ì‚¬ì§„ê³¼ ì„¤ëª…ì´ ì¼ì¹˜í•˜ë©°, êµ¬ì„±í’ˆ/ìƒ‰ìƒ/ë¼ë²¨ ëª¨ë‘ ë™ì¼', 'ticket', JSON '{{"source":"cs"}}'),
  ('B200', 'B200 ë¼ë²¨ ë¬¸êµ¬ê°€ ì‹ í˜• ê·œê²©ìœ¼ë¡œ ë³´ì„. ì„¤ëª…ì€ êµ¬í˜• ê·œê²©ìœ¼ë¡œ ì‘ì„±', 'ticket', JSON '{{"source":"cs"}}'),
  ('C100', 'C100 ì‚¬ìš©ì ë§¤ë‰´ì–¼ê³¼ ì œí’ˆ í˜ì´ì§€ì˜ ì‚¬ì´ì¦ˆ í‘œê¸°ê°€ ë™ì¼', 'ticket', JSON '{{"source":"cs"}}');

INSERT INTO `{PROJECT_ID}.{DATASET_ID}.feat_struct` (id, f1, f2, f3, meta) VALUES
  ('A100', 1.0, 0.2,  0.8, JSON '{{"qc_score":0.4}}'),
  ('A200', 0.9, 0.1,  0.7, JSON '{{"qc_score":0.3}}'),
  ('A300', 0.8, 0.15, 0.9, JSON '{{"qc_score":0.35}}'),
  ('B100', 0.1, 0.8,  0.2, JSON '{{"qc_score":0.9}}'),
  ('B200', 0.5, 0.3,  0.4, JSON '{{"qc_score":0.6}}'),
  ('C100', 0.2, 0.7,  0.3, JSON '{{"qc_score":0.85}}');
"""
client.query(sample_data_sql).result()
print("âœ… ìƒ˜í”Œ ë°ì´í„° ì‚½ì… ì™„ë£Œ")

# 4. ì„ë² ë”© ìƒì„± (ë”ë¯¸ ë²¡í„° ì‚¬ìš©)
print("\nğŸ§  4. ì„ë² ë”© ìƒì„± ì¤‘...")
embedding_sql = f"""
-- í…ìŠ¤íŠ¸ ì„ë² ë”© (ë”ë¯¸ ë²¡í„°)
CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.emb_view_t` AS
SELECT
  id,
  VECTOR_FROM_ARRAY([
    CASE WHEN id = 'A100' THEN [0.8, 0.1, 0.9, 0.2, 0.7, 0.3, 0.6, 0.4, 0.5, 0.8]
    WHEN id = 'A200' THEN [0.7, 0.2, 0.8, 0.3, 0.6, 0.4, 0.5, 0.5, 0.4, 0.7]
    WHEN id = 'A300' THEN [0.6, 0.3, 0.7, 0.4, 0.5, 0.5, 0.4, 0.6, 0.3, 0.6]
    WHEN id = 'B100' THEN [0.2, 0.8, 0.1, 0.9, 0.3, 0.7, 0.4, 0.6, 0.5, 0.2]
    WHEN id = 'B200' THEN [0.5, 0.4, 0.6, 0.5, 0.4, 0.6, 0.3, 0.7, 0.2, 0.5]
    WHEN id = 'C100' THEN [0.3, 0.7, 0.2, 0.8, 0.4, 0.6, 0.5, 0.5, 0.6, 0.3]
    ELSE [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
    END
  ]) AS vec
FROM `{PROJECT_ID}.{DATASET_ID}.raw_texts`;

-- êµ¬ì¡°í™” íŠ¹ì§• ë²¡í„°í™”
CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.feat_struct_vec` AS
WITH stats AS (
  SELECT
    AVG(f1) a1, STDDEV(f1) s1,
    AVG(f2) a2, STDDEV(f2) s2,
    AVG(f3) a3, STDDEV(f3) s3
  FROM `{PROJECT_ID}.{DATASET_ID}.feat_struct`
)
SELECT
  f.id,
  VECTOR_FROM_ARRAY([
    SAFE_DIVIDE(f1 - a1, NULLIF(s1,0)),
    SAFE_DIVIDE(f2 - a2, NULLIF(s2,0)),
    SAFE_DIVIDE(f3 - a3, NULLIF(s3,0))
  ]) AS vec
FROM `{PROJECT_ID}.{DATASET_ID}.feat_struct` f, stats;

-- ë©€í‹°ëª¨ë‹¬ ê²°í•©
CREATE OR REPLACE TABLE `{PROJECT_ID}.{DATASET_ID}.emb_stitched` AS
WITH keys AS (
  SELECT id AS k FROM `{PROJECT_ID}.{DATASET_ID}.raw_texts`
  UNION DISTINCT
  SELECT id FROM `{PROJECT_ID}.{DATASET_ID}.feat_struct`
)
SELECT
  k AS key,
  VECTOR_CONCAT(
    (SELECT vec FROM `{PROJECT_ID}.{DATASET_ID}.emb_view_t` WHERE id = k),
    (SELECT vec FROM `{PROJECT_ID}.{DATASET_ID}.feat_struct_vec` WHERE id = k)
  ) AS vec,
  1.0 AS alpha,
  0.5 AS beta
FROM keys;
"""
client.query(embedding_sql).result()
print("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ")

# 5. ORI ìµœì í™” ê³„ì‚°
print("\nğŸ¯ 5. ORI ìµœì í™” ê³„ì‚° ì¤‘...")
ori_sql = f"""
WITH query_embedding AS (
  SELECT VECTOR_FROM_ARRAY([0.8, 0.1, 0.9, 0.2, 0.7, 0.3, 0.6, 0.4, 0.5, 0.8, 1.0, 0.2, 0.8]) AS qvec
),
semantic_distances AS (
  SELECT 
    s.key,
    VECTOR_DISTANCE(s.vec, q.qvec) AS semantic_dist,
    SAFE_DIVIDE(VECTOR_DISTANCE(s.vec, q.qvec), 2.0) AS norm_semantic_dist
  FROM `{PROJECT_ID}.{DATASET_ID}.emb_stitched` s, query_embedding q
),
rule_based_scores AS (
  SELECT 
    id,
    CASE 
      WHEN REGEXP_CONTAINS(body, r'(ë¶ˆì¼ì¹˜|ëª¨ìˆœ|ë‹¤ë¦„|í‹€ë¦¼|ì˜ëª»)') THEN 0.8
      WHEN REGEXP_CONTAINS(body, r'(ì¼ì¹˜|ë™ì¼|ê°™ìŒ|ì •í™•)') THEN 0.2
      ELSE 0.5
    END AS keyword_score,
    CAST(JSON_EXTRACT_SCALAR(meta, '$.qc_score') AS FLOAT64) AS struct_score
  FROM `{PROJECT_ID}.{DATASET_ID}.raw_texts` t
  LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.feat_struct` f ON t.id = f.id
),
ori_calculation AS (
  SELECT 
    s.key,
    s.semantic_dist,
    s.norm_semantic_dist,
    r.keyword_score,
    r.struct_score,
    0.7 * s.norm_semantic_dist + 0.3 * (r.keyword_score + r.struct_score) / 2 AS ori_score,
    CASE 
      WHEN 0.7 * s.norm_semantic_dist + 0.3 * (r.keyword_score + r.struct_score) / 2 > 0.7 THEN 'HIGH'
      WHEN 0.7 * s.norm_semantic_dist + 0.3 * (r.keyword_score + r.struct_score) / 2 > 0.4 THEN 'MEDIUM'
      ELSE 'LOW'
    END AS risk_level
  FROM semantic_distances s
  LEFT JOIN rule_based_scores r ON s.key = r.id
)

SELECT 
  o.key,
  o.ori_score,
  o.risk_level,
  o.semantic_dist,
  o.keyword_score,
  o.struct_score,
  t.body,
  t.kind,
  CASE 
    WHEN REGEXP_CONTAINS(t.body, r'(ë¶ˆì¼ì¹˜|ëª¨ìˆœ|ë‹¤ë¦„)') THEN 1.0
    ELSE 0.0
  END AS baseline_score
FROM ori_calculation o
LEFT JOIN `{PROJECT_ID}.{DATASET_ID}.raw_texts` t ON o.key = t.id
ORDER BY o.ori_score DESC
"""
ori_results = client.query(ori_sql).to_dataframe()
print("âœ… ORI ê³„ì‚° ì™„ë£Œ")

# 6. ê²°ê³¼ ì‹œê°í™”
print("\nğŸ“Š 6. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”")

# ORI ì ìˆ˜ ë¶„í¬
plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
sns.barplot(data=ori_results, x='key', y='ori_score', hue='risk_level')
plt.title('ORI ì ìˆ˜ë³„ ìœ„í—˜ë„ ë¶„ë¥˜')
plt.xticks(rotation=45)

plt.subplot(2, 2, 2)
sns.scatterplot(data=ori_results, x='semantic_dist', y='ori_score', hue='risk_level', size='keyword_score')
plt.title('ì˜ë¯¸ì  ê±°ë¦¬ vs ORI ì ìˆ˜')

plt.subplot(2, 2, 3)
risk_counts = ori_results['risk_level'].value_counts()
plt.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%')
plt.title('ìœ„í—˜ë„ ë¶„í¬')

plt.subplot(2, 2, 4)
comparison_data = ori_results[['key', 'ori_score', 'baseline_score']].set_index('key')
comparison_data.plot(kind='bar', ax=plt.gca())
plt.title('ORI vs ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥
print("\nğŸ¯ ORI ë¶„ì„ ê²°ê³¼:")
display(ori_results[['key', 'ori_score', 'risk_level', 'body']])

# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
print("\nğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
total_cases = len(ori_results)
correct_predictions = len(ori_results[ori_results['ori_score'] > 0.4])
accuracy = correct_predictions / total_cases

print(f"ì „ì²´ ì‚¬ë¡€: {total_cases}")
print(f"ì •í™•í•œ ì˜ˆì¸¡: {correct_predictions}")
print(f"ì •í™•ë„: {accuracy:.2%}")

# Before/After ë¹„êµ
print("\nğŸ”„ Before/After ë¹„êµ:")
baseline_accuracy = ori_results['baseline_score'].mean()
ori_accuracy = (ori_results['ori_score'] > 0.4).mean()

print(f"ë² ì´ìŠ¤ë¼ì¸ ì •í™•ë„: {baseline_accuracy:.2%}")
print(f"ORI ì •í™•ë„: {ori_accuracy:.2%}")
print(f"ê°œì„ ìœ¨: {((ori_accuracy - baseline_accuracy) / baseline_accuracy * 100):.1f}%")

print("\nğŸ‰ Multimodal Descent ë°ëª¨ ì™„ë£Œ!")
print("=" * 60)
