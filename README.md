# Descent: Multimodal Discrepancy Detection System

A championship-level multimodal AI system for detecting discrepancies across text, image, and structured data using Google Cloud BigQuery AI and Vertex AI.

## ğŸ”— Quick Links

- ğŸ§  **Writeup**: [Kaggle Writeup](docs/KAGGLE_WRITEUP.md)
- ğŸ’» **GitHub**: https://github.com/tongro2025/Descent-AI
- ğŸ¬ **Demo Video**: [YouTube Demo](https://youtu.be/PX92XztRlSQ)
- ğŸ“¦ **Submission Bundle**: See `reports/` & `artifacts/` directories
- ğŸ“„ **License**: CC BY 4.0 (per competition rules; commercial use permitted)

## ğŸ“‹ Data Preparation

**âš ï¸ IMPORTANT: Competition data is not included in this repository.**

To reproduce the results, you need to:

1. **Download competition data** from Kaggle (following competition rules)
2. **Place data files** in the `data/` directory:
   - `raw_texts.csv` - Product descriptions and manuals
   - `feat_struct.csv` - Structured features
   - `struct_embeddings.csv` - Pre-computed embeddings
   - `text_embeddings.csv` - Text embeddings

3. **Set up environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your GCP project details
   ```

4. **Run the pipeline**:
   ```bash
   python descent_cli.py run --mode vertex
   ```

## ğŸ† Key Features

- **3 Embedding Options**: Vertex AI, Open Source, Native BigQuery AI
- **Real Multimodal Integration**: Text (768D) + Image (1408D) + Structured (3D) = 2179D
- **100% Recall**: Perfect recall on labeled mismatches (with large F1 and latency/cost wins)
- **Production Ready**: Dry run, retry logic, cost monitoring
- **Complete Automation**: CLI + Makefile for full automation

## ğŸš€ Quick Start

### Prerequisites

- Google Cloud Project with BigQuery and Vertex AI enabled
- Python 3.8+
- Google Cloud SDK installed and authenticated

**Enable required APIs:**
```bash
gcloud services enable bigquery.googleapis.com aiplatform.googleapis.com
```

### Environment Setup

1. **Copy environment template**:
   ```bash
   cp env.example .env
   ```

2. **Configure your environment**:
   Edit `.env` file with your actual values:
   ```bash
   # Required: Your Google Cloud Project ID
   GCP_PROJECT=your-actual-project-id
   
   # Optional: Customize other settings
   BQ_DATASET=descent_demo
   BQ_LOCATION=US
   USE_REAL_EMBEDDINGS=true
   USE_MULTIMODAL=false
   ```

3. **Set up Google Cloud authentication**:
   ```bash
   gcloud auth login
   gcloud config set project your-actual-project-id
   ```

### Installation

```bash
# Clone the repository
git clone https://github.com/tongro2025/Descent-AI.git
cd Descent-AI

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Initialize project
python descent_cli.py init --project-id YOUR_PROJECT_ID --dataset-id descent_demo
```

### Basic Usage

```bash
# Generate embeddings
python descent_cli.py embed

# Run ORI analysis
python descent_cli.py ori --weight 0.7 --threshold 0.3

# Generate evaluation report
python descent_cli.py report --modes text multimodal native

# Run integration tests
python descent_cli.py test --test-mode mini
```

## ğŸ¯ Architecture

### Embedding Options

1. **Option A: Native BigQuery AI**
   - Uses `ML.GENERATE_EMBEDDING` (e.g., model='text-embedding-005')
   - Direct SQL-based embedding generation
   - Requires BigQuery AI permissions

2. **Option B: Vertex AI Python SDK**
   - Uses `text-embedding-005` model (768 dimensions)
   - Python-based embedding generation
   - Uploads to BigQuery for analysis

3. **Option C: Open Source Models**
   - Uses SentenceTransformers `all-MiniLM-L6-v2` (384 dimensions)
   - Local embedding generation
   - Fallback option for testing

### Multimodal Integration

- **Text Embeddings**: Vertex AI text-embedding-005 (768D)
- **Image Embeddings**: Vertex AI multimodalembedding@001 (1408D)
- **Structured Features**: Z-score normalized (3D)
- **Combined**: ARRAY_CONCAT for multimodal fusion (2179D)

Example SQL:
```sql
SELECT ARRAY_CONCAT(t.text_vec, i.image_vec, s.struct_vec) AS emb_stitched FROM ...
```

### ORI Algorithm

The ORI (Discrepancy Index) algorithm combines:
- **Semantic Distance**: Cosine similarity between embeddings
- **Rule-based Score**: Keyword matching for discrepancy terms
- **Weighted Combination**: `ORI = w * semantic_distance + (1-w) * rule_score`

## ğŸ“Š Performance Results

| Metric | Keyword Search | Descent AI | Improvement |
|--------|----------------|------------|-------------|
| **Accuracy** | 33% | 50% | +51.5% |
| **Precision** | 31% | 50% | +61.3% |
| **Recall** | 25% | 100% | +300% |
| **F1 Score** | 28% | 66.7% | +138.2% |
| **Processing Time** | 5 min | 1.22 s | -99.8% |
| **Cost / 10k items** | $500 | $0.018 | -99.6% |

## ğŸ› ï¸ Advanced Usage

### Configuration

Edit `config.yaml` to customize settings:

```yaml
project_id: "your-project-id"
dataset_id: "descent_demo"
location: "US"
mode: "vertex"  # vertex, oss, native
dry_run: false
ori_weight: 0.7
ori_threshold: 0.3
```

### CLI Commands

```bash
# Project management
python descent_cli.py init --project-id PROJECT_ID
python descent_cli.py status
python descent_cli.py clean

# Pipeline execution
python descent_cli.py embed --dry-run
python descent_cli.py stitch
python descent_cli.py ori --weight 0.8 --threshold 0.2

# Evaluation and reporting
python descent_cli.py report --output-format markdown
python descent_cli.py test --test-mode full

# Development tools
make install
make lint
make format
make bundle
```

### Makefile Commands

```bash
# Basic operations
make init          # Initialize project
make embed         # Generate embeddings
make stitch        # Multimodal stitching
make ori           # ORI analysis
make report        # Generate evaluation report
make test          # Integration tests

# Development
make install       # Install dependencies
make lint          # Code linting
make format        # Code formatting
make bundle        # Create submission bundle

# CI/CD
make ci-test       # CI tests
make ci-report     # CI reports
```

## ğŸ“ Project Structure

```
Descent-AI/
â”œâ”€â”€ ğŸ“„ Core Files
â”‚   â”œâ”€â”€ README.md                    # Project overview and usage guide
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md         # Detailed project structure
â”‚   â”œâ”€â”€ config.yaml                  # Main configuration
â”‚   â”œâ”€â”€ Makefile                     # Build automation
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ ğŸ Source Code (src/descent/)
â”‚   â”œâ”€â”€ descent_cli.py               # Command-line interface
â”‚   â”œâ”€â”€ descent_pipeline_v2.py       # Core pipeline engine (319 lines)
â”‚   â”œâ”€â”€ bq.py                        # BigQuery client wrapper
â”‚   â”œâ”€â”€ config.py                    # Configuration management
â”‚   â””â”€â”€ eval_harness.py              # Evaluation system
â”‚
â”œâ”€â”€ ğŸ—„ï¸ SQL Scripts (22 files)
â”‚   â”œâ”€â”€ 01_schema.sql                # Database schema
â”‚   â”œâ”€â”€ 02_embeddings.sql            # Embedding generation
â”‚   â”œâ”€â”€ 03_incremental_idempotency.sql # Incremental processing
â”‚   â”œâ”€â”€ 05_sample_data.sql           # Sample data insertion
â”‚   â”œâ”€â”€ 08_create_vector_index.sql   # Vector index creation
â”‚   â”œâ”€â”€ 12_ori_optimization.sql      # ORI algorithm optimization
â”‚   â””â”€â”€ ...                          # 16 additional SQL scripts
â”‚
â”œâ”€â”€ ğŸ“š Documentation (docs/)
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # System architecture
â”‚   â”œâ”€â”€ QUICK_START.md               # Quick reproduction guide
â”‚   â”œâ”€â”€ REAL_ENVIRONMENT_GUIDE.md    # Production setup
â”‚   â”œâ”€â”€ KAGGLE_WRITEUP.md            # Competition writeup
â”‚   â””â”€â”€ ...                          # 6 additional guides
â”‚
â”œâ”€â”€ ğŸ“Š Reports & Results (reports/)
â”‚   â”œâ”€â”€ evaluation_report.md         # Comprehensive evaluation
â”‚   â”œâ”€â”€ multimodal_evidence_report.md # Multimodal proof
â”‚   â”œâ”€â”€ performance_measurement_results.json # Performance data
â”‚   â””â”€â”€ ...                          # 6 additional reports
â”‚
â”œâ”€â”€ ğŸ“ˆ Sample Data (data/sample/)
â”‚   â”œâ”€â”€ raw_texts.csv                # Sample text data
â”‚   â”œâ”€â”€ feat_struct.csv              # Sample structured features
â”‚   â”œâ”€â”€ text_embeddings.csv          # Sample text embeddings
â”‚   â””â”€â”€ struct_embeddings.csv        # Sample structured embeddings
â”‚
â””â”€â”€ ğŸ› ï¸ Tools & Scripts
    â”œâ”€â”€ run_demo.sh                  # Complete demo script
    â”œâ”€â”€ scripts/validate_pipeline.py # Pipeline validation
    â”œâ”€â”€ scripts/check_gitignore.sh   # Security verification
    â””â”€â”€ artifacts/                   # Generated outputs
```

**ğŸ“‹ Detailed Structure**: See [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) for complete file inventory.

## ğŸ”§ Technical Details

### BigQuery Schema

- `raw_texts`: Source text data with content hashing
- `emb_view_t_vertex`: Vertex AI text embeddings (768D)
- `emb_view_i_real`: Vertex AI image embeddings (1408D)
- `feat_struct_vec`: Structured feature vectors (3D)
- `emb_stitched_real`: Multimodal combined embeddings (2179D)
- `report_ori`: ORI analysis results
- `eval_metrics`: Performance evaluation metrics

### Key Technologies

- **Google Cloud BigQuery**: Data warehouse and SQL processing
- **Vertex AI**: Google's ML platform for embeddings
- **BigQuery AI**: Native AI functions in BigQuery
- **SentenceTransformers**: Open source embedding models
- **Python**: Pipeline orchestration and data processing
- **Typer**: Modern CLI framework
- **Pandas**: Data manipulation and analysis

## ğŸ¬ Demo Materials

### CLI Demo
```bash
./run_demo.sh  # Complete CLI demonstration
```

### BigQuery Screenshots
- `artifacts/01_basic_data.sql` - Basic data verification
- `artifacts/02_text_embeddings.sql` - Text embedding results
- `artifacts/03_image_embeddings.sql` - Image embedding results
- `artifacts/04_ori_results.sql` - ORI analysis results
- `artifacts/05_multimodal_comparison.sql` - Multimodal comparison
- `artifacts/06_embedding_dimensions.sql` - Dimension comparison
- `artifacts/07_evaluation_metrics.sql` - Performance metrics
- `artifacts/08_multimodal_stitched.sql` - Multimodal integration

### Evidence Materials
- `artifacts/multimodal_evidence_report.md` - Multimodal proof
- `artifacts/evaluation_report.md` - Performance evaluation
- `artifacts/bq_capture_summary.md` - BigQuery results summary

## ğŸ… Championship Features

### P0: Reliability & Reproducibility
- âœ… Dry run + Idempotency
- âœ… Error handling & retry logic
- âœ… Unified configuration (config.yaml)
- âœ… Schema versioning

### P1: Performance & Scale
- âœ… Incremental embedding
- âœ… Hash-based idempotency
- âœ… Partitioning & clustering
- âœ… Cost monitoring

### P2: Quality & Validation
- âœ… Evaluation harness
- âœ… Externalized ORI parameters
- âœ… Cost reporting
- âœ… Performance metrics

### P3: Code & CI/CD
- âœ… CLI integration
- âœ… Test & linting
- âœ… Makefile automation
- âœ… Documentation

## ğŸ“ˆ Business Impact

- **Recall**: 100% on labeled mismatches (with large F1 and latency/cost wins)
- **Efficiency**: Automated pipeline reduces manual effort
- **Scalability**: Handles large datasets with incremental processing
- **Reliability**: Production-ready with error handling
- **Flexibility**: Multiple embedding options for different scenarios

## ğŸ”’ Security & Privacy

### Data Protection
- **No sensitive data**: This repository contains no actual competition data
- **Environment variables**: All sensitive configuration is externalized
- **Git ignore**: Sensitive files are automatically excluded from version control
- **Security warning**: Never commit .env files or service account keys. Use .env.example as template only.

### Safe Configuration
```bash
# Never commit these files:
.env
*.key
service-account*.json
credentials.json
```

### Compliance
- **CC BY 4.0 License**: Ensures commercial use is permitted
- **Open Source**: All dependencies use permissive licenses
- **No proprietary data**: Only uses publicly available datasets

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests: `make test`
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the Creative Commons Attribution 4.0 International License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Google Cloud BigQuery AI team
- Vertex AI platform
- SentenceTransformers community
- Kaggle BigQuery AI Hackathon organizers

## ğŸš€ One-line Recipes

```bash
# Quick start
python descent_cli.py run --mode vertex --dry-run False

# Generate report
python descent_cli.py report --modes text multimodal native

# Test with sample data
python descent_cli.py test --test-mode mini
```

---

**Descent**: Where multimodal AI meets championship-level engineering ğŸ†