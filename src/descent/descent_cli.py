#!/usr/bin/env python3
"""
Descent CLI - ìš°ìŠ¹ ë ˆë²¨ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤
P3: ì½”ë“œÂ·CI/CDÂ·ê°€ë…ì„±
"""

import typer
import yaml
import json
from pathlib import Path
from typing import Optional, List
import subprocess
import sys
from descent_pipeline_v2 import PipelineRunner, PipelineConfig, load_config
from eval_harness import DescentEvaluator

app = typer.Typer(help="Descent Pipeline CLI - Championship Level")

@app.command()
def init(
    project_id: str = typer.Option(..., help="GCP Project ID"),
    dataset_id: str = typer.Option("descent_demo", help="BigQuery Dataset ID"),
    location: str = typer.Option("US", help="BigQuery Region"),
    mode: str = typer.Option("vertex", help="Execution mode (vertex/oss/native)"),
    config_file: str = typer.Option("config.yaml", help="Configuration file path")
):
    """Initialize project"""
    typer.echo(f"ğŸš€ Initializing Descent project: {project_id}.{dataset_id}")
    
    config = PipelineConfig(
        project_id=project_id,
        dataset_id=dataset_id,
        location=location,
        mode=mode
    )
    
    # Save configuration file
    with open(config_file, 'w') as f:
        yaml.dump(config.__dict__, f, default_flow_style=False)
    
    typer.echo(f"âœ… Configuration file created: {config_file}")
    
    # Create basic directories
    Path("artifacts").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)
    
    typer.echo("âœ… Project structure created successfully")

@app.command()
def embed(
    config_file: str = typer.Option("config.yaml", help="Configuration file path"),
    dry_run: bool = typer.Option(False, help="Dry run mode"),
    incremental: bool = typer.Option(True, help="Use incremental embedding")
):
    """Generate embeddings"""
    typer.echo("ğŸ§  Starting embedding generation")
    
    config = load_config(config_file)
    config.dry_run = dry_run
    config.enable_incremental = incremental
    
    runner = PipelineRunner(config)
    
    try:
        runner.run_pipeline()
        typer.echo("âœ… Embedding generation completed")
    except Exception as e:
        typer.echo(f"âŒ Embedding generation failed: {e}")
        raise typer.Exit(1)

@app.command()
def stitch(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    dry_run: bool = typer.Option(False, help="ë“œë¼ì´ëŸ° ëª¨ë“œ")
):
    """ë©€í‹°ëª¨ë‹¬ ìŠ¤í‹°ì¹­"""
    typer.echo("ğŸ”— ë©€í‹°ëª¨ë‹¬ ìŠ¤í‹°ì¹­ ì‹œì‘")
    
    config = load_config(config_file)
    config.dry_run = dry_run
    
    runner = PipelineRunner(config)
    
    # ìŠ¤í‹°ì¹­ë§Œ ì‹¤í–‰
    runner.add_content_hash()
    runner.create_ori_params_table()
    
    typer.echo("âœ… ìŠ¤í‹°ì¹­ ì™„ë£Œ")

@app.command()
def ori(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    weight: float = typer.Option(0.7, help="ORI ê°€ì¤‘ì¹˜"),
    threshold: float = typer.Option(0.3, help="ORI ì„ê³„ê°’"),
    dry_run: bool = typer.Option(False, help="ë“œë¼ì´ëŸ° ëª¨ë“œ")
):
    """ORI ë¶„ì„ ì‹¤í–‰"""
    typer.echo("ğŸ¯ ORI ë¶„ì„ ì‹œì‘")
    
    config = load_config(config_file)
    config.ori_weight = weight
    config.ori_threshold = threshold
    config.dry_run = dry_run
    
    runner = PipelineRunner(config)
    
    try:
        runner.create_ori_params_table()
        runner.create_evaluation_harness()
        typer.echo("âœ… ORI ë¶„ì„ ì™„ë£Œ")
    except Exception as e:
        typer.echo(f"âŒ ORI ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)

@app.command()
def report(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    modes: List[str] = typer.Option(["text", "multimodal", "native"], help="í‰ê°€í•  ëª¨ë“œë“¤"),
    output_format: str = typer.Option("markdown", help="ì¶œë ¥ í˜•ì‹ (markdown/json/csv)")
):
    """í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±"""
    typer.echo("ğŸ“Š í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
    
    config = load_config(config_file)
    
    evaluator = DescentEvaluator(config.project_id, config.dataset_id)
    
    try:
        # ëª¨ë“œë³„ ë¹„êµ
        comparison_df = evaluator.compare_modes(modes)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = evaluator.generate_report(comparison_df)
        
        # ê²°ê³¼ ì €ì¥
        evaluator.save_results(comparison_df, report)
        
        # ì¶œë ¥ í˜•ì‹ì— ë”°ë¥¸ ê²°ê³¼ í‘œì‹œ
        if output_format == "markdown":
            typer.echo("\n" + report)
        elif output_format == "json":
            results_dict = comparison_df.to_dict('records')
            typer.echo(json.dumps(results_dict, indent=2, ensure_ascii=False))
        elif output_format == "csv":
            typer.echo(comparison_df.to_csv(index=False))
        
        typer.echo("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        
    except Exception as e:
        typer.echo(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise typer.Exit(1)

@app.command()
def test(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    test_mode: str = typer.Option("mini", help="í…ŒìŠ¤íŠ¸ ëª¨ë“œ (mini/full)")
):
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    typer.echo("ğŸ§ª í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    config = load_config(config_file)
    
    if test_mode == "mini":
        # ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸: OSS ëª¨ë“œë¡œ ë¹ ë¥¸ ê²€ì¦
        config.mode = "oss"
        config.dry_run = True
        
        runner = PipelineRunner(config)
        
        try:
            runner.run_pipeline()
            typer.echo("âœ… ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ í†µê³¼")
        except Exception as e:
            typer.echo(f"âŒ ë¯¸ë‹ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            raise typer.Exit(1)
    
    elif test_mode == "full":
        # ì „ì²´ í…ŒìŠ¤íŠ¸: ëª¨ë“  ëª¨ë“œ ê²€ì¦
        modes = ["text", "multimodal", "native"]
        
        for mode in modes:
            typer.echo(f"ğŸ” {mode} ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì¤‘...")
            config.mode = mode
            config.dry_run = True
            
            runner = PipelineRunner(config)
            
            try:
                runner.run_pipeline()
                typer.echo(f"âœ… {mode} ëª¨ë“œ í…ŒìŠ¤íŠ¸ í†µê³¼")
            except Exception as e:
                typer.echo(f"âŒ {mode} ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                raise typer.Exit(1)
        
        typer.echo("âœ… ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼")

@app.command()
def clean(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ"),
    artifacts: bool = typer.Option(True, help="ì•„í‹°íŒ©íŠ¸ ì‚­ì œ"),
    logs: bool = typer.Option(True, help="ë¡œê·¸ ì‚­ì œ"),
    tables: bool = typer.Option(False, help="BigQuery í…Œì´ë¸” ì‚­ì œ (ì£¼ì˜!)")
):
    """ì •ë¦¬ ì‘ì—…"""
    typer.echo("ğŸ§¹ ì •ë¦¬ ì‘ì—… ì‹œì‘")
    
    if artifacts:
        import shutil
        if Path("artifacts").exists():
            shutil.rmtree("artifacts")
            typer.echo("âœ… ì•„í‹°íŒ©íŠ¸ ì‚­ì œ ì™„ë£Œ")
    
    if logs:
        import shutil
        if Path("logs").exists():
            shutil.rmtree("logs")
            typer.echo("âœ… ë¡œê·¸ ì‚­ì œ ì™„ë£Œ")
    
    if tables:
        if typer.confirm("âš ï¸  BigQuery í…Œì´ë¸”ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
            config = load_config(config_file)
            client = bigquery.Client(project=config.project_id)
            
            # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            tables = client.list_tables(config.dataset_id)
            
            for table in tables:
                client.delete_table(f"{config.project_id}.{config.dataset_id}.{table.table_id}")
                typer.echo(f"âœ… í…Œì´ë¸” ì‚­ì œ: {table.table_id}")
    
    typer.echo("âœ… ì •ë¦¬ ì‘ì—… ì™„ë£Œ")

@app.command()
def status(
    config_file: str = typer.Option("config.yaml", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
):
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    typer.echo("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
    
    config = load_config(config_file)
    
    # ì„¤ì • ì •ë³´
    typer.echo(f"í”„ë¡œì íŠ¸: {config.project_id}")
    typer.echo(f"ë°ì´í„°ì…‹: {config.dataset_id}")
    typer.echo(f"ëª¨ë“œ: {config.mode}")
    typer.echo(f"ìœ„ì¹˜: {config.location}")
    
    # ì•„í‹°íŒ©íŠ¸ í™•ì¸
    artifacts_dir = Path("artifacts")
    if artifacts_dir.exists():
        files = list(artifacts_dir.glob("*"))
        typer.echo(f"ì•„í‹°íŒ©íŠ¸ íŒŒì¼ ìˆ˜: {len(files)}")
        
        for file in files:
            typer.echo(f"  - {file.name}")
    else:
        typer.echo("ì•„í‹°íŒ©íŠ¸ ì—†ìŒ")
    
    # BigQuery ì—°ê²° í™•ì¸
    try:
        from google.cloud import bigquery
        client = bigquery.Client(project=config.project_id)
        datasets = list(client.list_datasets())
        typer.echo(f"BigQuery ì—°ê²°: âœ… ({len(datasets)}ê°œ ë°ì´í„°ì…‹)")
    except Exception as e:
        typer.echo(f"BigQuery ì—°ê²°: âŒ ({e})")

if __name__ == "__main__":
    app()
